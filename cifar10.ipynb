{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjgz3JSqD2rYzPuQA6QSNk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyzakturk/Cifar10-GAN/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da_V6BmNU2if"
      },
      "outputs": [],
      "source": [
        "## Keras arkasında tensorflow backend kullanıyoruz\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow' \n",
        "os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
        "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu\n",
        "from keras.initializers import RandomNormal\n",
        "conv_init = RandomNormal(0, 0.02)\n",
        "gamma_init = RandomNormal(1., 0.02)"
      ],
      "metadata": {
        "id": "BJPhgRaaVGlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DCGAN_D(isize, nz, nc, ndf, n_extra_layers=0):\n",
        "    assert isize%2==0\n",
        "    _ = inputs = Input(shape=(nc, isize, isize))\n",
        "    _ = Conv2D(filters=ndf, kernel_size=4, strides=2, use_bias=False,\n",
        "                        padding = \"same\",\n",
        "                        kernel_initializer = conv_init, \n",
        "                        name = 'initial.conv.{0}-{1}'.format(nc, ndf)             \n",
        "                        ) (_)\n",
        "    _ = LeakyReLU(alpha=0.2, name = 'initial.relu.{0}'.format(ndf))(_)\n",
        "    csize, cndf = isize// 2, ndf\n",
        "    while csize > 5:\n",
        "        assert csize%2==0\n",
        "        in_feat = cndf\n",
        "        out_feat = cndf*2\n",
        "        _ = Conv2D(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
        "                        padding = \"same\",\n",
        "                        kernel_initializer = conv_init,\n",
        "                        name = 'pyramid.{0}-{1}.conv'.format(in_feat, out_feat)             \n",
        "                        ) (_)\n",
        "        if 0: # toggle batchnormalization\n",
        "            _ = BatchNormalization(name = 'pyramid.{0}.batchnorm'.format(out_feat),                                   \n",
        "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                                   gamma_initializer = gamma_init, \n",
        "                                  )(_, training=1)        \n",
        "        _ = LeakyReLU(alpha=0.2, name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
        "        csize, cndf = (csize+1)//2, cndf*2\n",
        "    _ = Conv2D(filters=1, kernel_size=csize, strides=1, use_bias=False,\n",
        "                        kernel_initializer = conv_init,\n",
        "                        name = 'final.{0}-{1}.conv'.format(cndf, 1)         \n",
        "                        ) (_)\n",
        "    outputs = Flatten()(_)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "3iukTJqvVJWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ayırt edici ağ yapısı TensorFlow'un CNN modeli gibi olsa da 3 evrişimsel sinir ağı ve 4x4 filtreden oluşmaktadır."
      ],
      "metadata": {
        "id": "AYlaqYCOVUCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Üretici ağ yapısına bakalım. Kernel boyutu 4x4 olan ve 3D evrişim modelinin transpose halini içeren üç adet ters evrişim işleminden oluşur. Sonuçta 32x32x3 resimler oluşturur. Burada hiperbolik tanjant aktivasyon fonksiyonu kullanılmıştır."
      ],
      "metadata": {
        "id": "N9Xr6v9cVgSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DCGAN_G(isize, nz, nc, ngf, n_extra_layers=0):\n",
        "    cngf= ngf//2\n",
        "    tisize = isize\n",
        "    while tisize > 5:\n",
        "        cngf = cngf * 2\n",
        "        assert tisize%2==0\n",
        "        tisize = tisize // 2\n",
        "    _ = inputs = Input(shape=(nz,))\n",
        "    _ = Reshape((nz, 1,1))(_)\n",
        "    _ = Conv2DTranspose(filters=cngf, kernel_size=tisize, strides=1, use_bias=False,\n",
        "                           kernel_initializer = conv_init, \n",
        "                           name = 'initial.{0}-{1}.convt'.format(nz, cngf))(_)\n",
        "    _ = BatchNormalization(gamma_initializer = gamma_init, momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                               name = 'initial.{0}.batchnorm'.format(cngf))(_, training=1)\n",
        "    _ = Activation(\"relu\", name = 'initial.{0}.relu'.format(cngf))(_)\n",
        "    csize, cndf = tisize, cngf\n",
        "    \n",
        "\n",
        "    while csize < isize//2:\n",
        "        in_feat = cngf\n",
        "        out_feat = cngf//2\n",
        "        _ = Conv2DTranspose(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
        "                        kernel_initializer = conv_init, padding=\"same\",\n",
        "                        name = 'pyramid.{0}-{1}.convt'.format(in_feat, out_feat)             \n",
        "                        ) (_)\n",
        "        _ = BatchNormalization(gamma_initializer = gamma_init, \n",
        "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
        "                                   name = 'pyramid.{0}.batchnorm'.format(out_feat))(_, training=1)\n",
        "        \n",
        "        _ = Activation(\"relu\", name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
        "        csize, cngf = csize*2, cngf//2\n",
        "    _ = Conv2DTranspose(filters=nc, kernel_size=4, strides=2, use_bias=False,\n",
        "                        kernel_initializer = conv_init, padding=\"same\",\n",
        "                        name = 'final.{0}-{1}.convt'.format(cngf, nc)\n",
        "                        )(_)\n",
        "    outputs = Activation(\"tanh\", name = 'final.{0}.tanh'.format(nc))(_)\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "wu6SRQfHVPCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametre tanımlarını yapalım"
      ],
      "metadata": {
        "id": "fBylJZC5VxAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nc = 3 # number of channels\n",
        "nz = 100\n",
        "ngf = 64 # number of discriminator  features \n",
        "ndf = 64 # number of generator features\n",
        "n_extra_layers = 0\n",
        "Diters = 5 # iteration dimension\n",
        "λ = 10 # wasserstein loss katsayısı\n",
        "\n",
        "imageSize = 32\n",
        "batchSize = 64\n",
        "lrD = 1e-4 # ayırt edici ağ öğrenme katsayısı\n",
        "lrG = 1e-4 # üretici ağ ağ öğrenme katsayısı\n"
      ],
      "metadata": {
        "id": "sIWR2piEVpnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netD = DCGAN_D(imageSize, nz, nc, ndf, n_extra_layers)\n",
        "netD.summary()\n",
        "netG = DCGAN_G(imageSize, nz, nc, ngf, n_extra_layers)\n",
        "netG.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1BcQxT-VupT",
        "outputId": "5ba56c6d-5c14-4c28-a95c-4f8b92440482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3, 32, 32)]       0         \n",
            "                                                                 \n",
            " initial.conv.3-64 (Conv2D)  (None, 64, 16, 16)        3072      \n",
            "                                                                 \n",
            " initial.relu.64 (LeakyReLU)  (None, 64, 16, 16)       0         \n",
            "                                                                 \n",
            " pyramid.64-128.conv (Conv2D  (None, 128, 8, 8)        131072    \n",
            " )                                                               \n",
            "                                                                 \n",
            " pyramid.128.relu (LeakyReLU  (None, 128, 8, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " pyramid.128-256.conv (Conv2  (None, 256, 4, 4)        524288    \n",
            " D)                                                              \n",
            "                                                                 \n",
            " pyramid.256.relu (LeakyReLU  (None, 256, 4, 4)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " final.256-1.conv (Conv2D)   (None, 1, 1, 1)           4096      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 662,528\n",
            "Trainable params: 662,528\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 100, 1, 1)         0         \n",
            "                                                                 \n",
            " initial.100-256.convt (Conv  (None, 256, 4, 4)        409600    \n",
            " 2DTranspose)                                                    \n",
            "                                                                 \n",
            " initial.256.batchnorm (Batc  (None, 256, 4, 4)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " initial.256.relu (Activatio  (None, 256, 4, 4)        0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " pyramid.256-128.convt (Conv  (None, 128, 8, 8)        524288    \n",
            " 2DTranspose)                                                    \n",
            "                                                                 \n",
            " pyramid.128.batchnorm (Batc  (None, 128, 8, 8)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " pyramid.128.relu (Activatio  (None, 128, 8, 8)        0         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " pyramid.128-64.convt (Conv2  (None, 64, 16, 16)       131072    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " pyramid.64.batchnorm (Batch  (None, 64, 16, 16)       256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " pyramid.64.relu (Activation  (None, 64, 16, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " final.64-3.convt (Conv2DTra  (None, 3, 32, 32)        3072      \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " final.3.tanh (Activation)   (None, 3, 32, 32)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,069,824\n",
            "Trainable params: 1,068,928\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam"
      ],
      "metadata": {
        "id": "zgVI3tVZV93_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netD_real_input = Input(shape=(nc, imageSize, imageSize))\n",
        "noisev = Input(shape=(nz,))\n",
        "netD_fake_input = netG(noisev)\n",
        "\n",
        "ϵ_input = K.placeholder(shape=(None,1,1,1))\n",
        "netD_mixed_input = Input(shape=(nc, imageSize, imageSize),\n",
        "    tensor=ϵ_input * netD_real_input + (1-ϵ_input) * netD_fake_input)\n",
        "\n",
        "\n",
        "loss_real = K.mean(netD(netD_real_input))\n",
        "loss_fake = K.mean(netD(netD_fake_input))\n",
        "\n",
        "grad_mixed = K.gradients(netD(netD_mixed_input), [netD_mixed_input])[0]\n",
        "norm_grad_mixed = K.sqrt(K.sum(K.square(grad_mixed), axis=[1,2,3]))\n",
        "grad_penalty = K.mean(K.square(norm_grad_mixed -1))\n",
        "\n",
        "loss = loss_fake - loss_real + λ * grad_penalty\n",
        "\n",
        "\n",
        "training_updates = Adam(lr=lrD, beta_1=0.0, beta_2=0.9).get_updates(netD.trainable_weights,[],loss)\n",
        "netD_train = K.function([netD_real_input, noisev, ϵ_input],\n",
        "                        [loss_real, loss_fake],    \n",
        "                        training_updates)"
      ],
      "metadata": {
        "id": "xkyEG6zxWC_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -loss_fake \n",
        "training_updates = Adam(lr=lrG, beta_1=0.0, beta_2=0.9).get_updates(netG.trainable_weights,[], loss)\n",
        "netG_train = K.function([noisev], [loss], training_updates)"
      ],
      "metadata": {
        "id": "QKfSvrx3Xq38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tarfile\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "import os\n",
        "import urllib\n",
        "from urllib.request import urlretrieve\n",
        "def reporthook(a,b,c):\n",
        "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
        "tar_gz = \"cifar-10-python.tar.gz\"\n",
        "if not os.path.isfile(tar_gz):\n",
        "        print('Downloading data from %s' % url)\n",
        "        urlretrieve(url, tar_gz, reporthook=reporthook)\n",
        "\n",
        "import pickle\n",
        "train_X=[]\n",
        "train_y=[]\n",
        "tar_gz = \"cifar-10-python.tar.gz\"\n",
        "with tarfile.open(tar_gz) as tarf:\n",
        "    for i in range(1, 6):\n",
        "        dataset = \"cifar-10-batches-py/data_batch_%d\"%i\n",
        "        print(\"load\",dataset)\n",
        "        with tarf.extractfile(dataset) as f:\n",
        "            result = pickle.load(f, encoding='latin1')\n",
        "        train_X.extend( result['data'].reshape(-1,3,32,32)/255*2-1)\n",
        "        train_y.extend(result['labels'])\n",
        "    train_X=np.float32(train_X)\n",
        "    train_y=np.int32(train_y)\n",
        "    dataset = \"cifar-10-batches-py/test_batch\"\n",
        "    print(\"load\",dataset)\n",
        "    with tarf.extractfile(dataset) as f:\n",
        "        result = pickle.load(f, encoding='latin1')\n",
        "        test_X=np.float32(result['data'].reshape(-1,3,32,32)/255*2-1)\n",
        "        test_y=np.int32(result['labels'])\n",
        "        "
      ],
      "metadata": {
        "id": "7GDiboeGaIK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.concatenate([train_X, test_X])\n",
        "train_X = np.concatenate([train_X[:,:,:,::-1], train_X])"
      ],
      "metadata": {
        "id": "JG-nHVi7aMf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "def showX(X, rows=1):\n",
        "    assert X.shape[0]%rows == 0\n",
        "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
        "    # N*3072 -> N*3*32*32 -> 32 * 32N * 3\n",
        "    int_X = np.moveaxis(int_X.reshape(-1,3,32,32), 1, 3)\n",
        "    int_X = int_X.reshape(rows, -1, 32, 32,3).swapaxes(1,2).reshape(rows*32,-1, 3)\n",
        "    display(Image.fromarray(int_X))\n",
        "showX(train_X[:20])\n",
        "print(train_y[:20])\n",
        "name_array = np.array(\"airplane car bird cat deer dog frog horse boat truck\".split(' '))\n",
        "print(name_array[train_y[:20]])"
      ],
      "metadata": {
        "id": "CMAofOfvaSKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
      ],
      "metadata": {
        "id": "17uRVkRXaWIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "niter = 100\n",
        "gen_iterations = 0\n",
        "errG = 0\n",
        "targetD = np.float32([2]*batchSize+[-2]*batchSize)[:, None]\n",
        "targetG = np.ones(batchSize, dtype=np.float32)[:, None]\n",
        "for epoch in range(niter):\n",
        "    i = 0\n",
        "    np.random.shuffle(train_X)\n",
        "    batches = train_X.shape[0]//batchSize\n",
        "    while i < batches:\n",
        "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
        "            _Diters = 100\n",
        "        else:\n",
        "            _Diters = Diters\n",
        "        j = 0\n",
        "        while j < _Diters and i < batches:\n",
        "            j+=1\n",
        "            real_data = train_X[i*batchSize:(i+1)*batchSize]\n",
        "            i+=1\n",
        "            noise = np.random.normal(size=(batchSize, nz))        \n",
        "            ϵ = np.random.uniform(size=(batchSize, 1, 1 ,1))        \n",
        "            errD_real, errD_fake  = netD_train([real_data, noise, ϵ])\n",
        "            errD = errD_real - errD_fake\n",
        "       \n",
        "        if gen_iterations%500==0:\n",
        "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
        "            % (epoch, niter, i, batches, gen_iterations,errD, errG, errD_real, errD_fake), time.time()-t0)\n",
        "            fake = netG.predict(fixed_noise)\n",
        "            showX(fake, 4)\n",
        "        \n",
        "        noise = np.random.normal(size=(batchSize, nz))        \n",
        "        errG, = netG_train([noise])\n",
        "        gen_iterations+=1 \n",
        "        "
      ],
      "metadata": {
        "id": "hzS_WhHaaY0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}